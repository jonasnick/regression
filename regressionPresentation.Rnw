% regressionPresentationRnw
% R code style:
%\DefineVerbatimEnvironment{Sinput}{Verbatim}{xleftmargin=2em}
%\DefineVerbatimEnvironment{Soutput}{Verbatim}{xleftmargin=2em}
%\DefineVerbatimEnvironment{Scode}{Verbatim}{xleftmargin=2em}
%\fvset{listparameters={\setlength{\topsep}{0pt}}}
%\renewenvironment{Schunk}{\vspace{\topsep}}{\vspace{\topsep}}
\documentclass {beamer}
\usetheme{Rochester}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\begin{document}
%Shortens output lines
<<echo=false>>=
options(width=60)
options(continue=" ")
source("regressionFunctions.R")
@
\begin{frame}[fragile]{Lineare Regression: Least-squares, Maximum Likelihood und Bayes}
\tableofcontents
\end{frame}
\section{Dataset}
\begin{frame}[fragile]{Dataset}
\begin{small}
<<loadProfitData>>=
profitData <- read.table("ex1data2.txt", 
                            header=TRUE, sep=",")
head(profitData)
nrow(profitData)
@
\end{small}
\end{frame}
\begin{frame}[fragile]{Dataset}
\begin{small}
<<displayProfitData, fig=true, echo=false>>=
#lines(density(profitData$price))
#head(profitData$price)
#hist(profitData$price, breaks=10,prob=T)
pairs(profitData[,c(1,2,3)])
#plot(1:10)
@
\end{small}
\end{frame}
\begin{frame}[fragile]{Dataset}
\begin{small}
<<displayProfitData2, fig=true, echo=false, include=false,width=6,height=4>>=
#lines(density(profitData$price))
#head(profitData$price)
#hist(profitData$price, breaks=10,prob=T)
plot(price~house_size,data=profitData, xlab="Size of the house",
        yaxt="n",ylab="Price");
ymin=min(profitData[,3])
ymax=max(profitData[,3])
axis(2, at=c(ymin, (ymin+ymax)/2, ymax))
        
model<-lm(price~house_size,data=profitData)
abline(model)
#plot(1:10)
@
\begin{figure}[tbp]
\centering
\includegraphics{regressionPresentation-displayProfitData2}
\end{figure}
\end{small}
\end{frame}
\section{Lineare Regression: Hypothese}
\begin{frame}{Lineare Regression: Hypothese}
\begin{small}
\[
x = \begin{bmatrix} x_0\\x_1\\x_2\\\vdots\\x_n \end{bmatrix} \in \mathbb{R}^{n+1}, \theta = \begin{bmatrix} \theta_0\\\theta_1\\\theta_2\\\vdots\\\theta_n \end{bmatrix} \in \mathbb{R}^{n+1}
\]
\[
h_\theta(x)=\theta^Tx
\]
\[
h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\dots+\theta_nx_n
\]

\end{small}
\end{frame}
\section{Least Squares: Kostenfunktion}
\begin{frame}{Kostenfunktion}
\begin{small}
\[
J(\theta_0,\theta_1) = \frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})^2
\]
\[
\underset{\theta_0,\theta_1}{\operatorname{argmin}} J(\theta_0,\theta_1)
\]
\end{small}
\end{frame}

\section{Gradientenverfahren}
\begin{frame}{Gradientenverfahren}
\begin{small}
picture: gradient descent
\end{small}
\end{frame}
\begin{frame}{Analytische Lösung}
\begin{small}
möglich, aber wesentlich langsamer für große daten 
lineare regression hat eh nur ein minimum
\end{small}
\end{frame}

\section{Polynomielle Regression}
\begin{frame}{Polynomielle Regression}
\begin{small}
\[
h_\theta=\theta_0 + \theta_1x + \theta_2x^2 + \theta_3\sqrt{x}
\]

\end{small}
\end{frame}

\section{Logistische Regression}
\begin{frame}[fragile]{Logistische Regression}
<<loadAdmissionData,echo=FALSE>>=
admissionData <- read.table("admissionData.txt",header=TRUE,sep=",")
admissionData$admitted <- as.factor(admissionData$admitted)
@
<<sigmoidFunction, fig=true, echo=false, include=false,width=4,height=4>>=
par(cex.lab=1.2)
plot(g, xlim=c(-5,5))
@
\begin{columns}[T]
\begin{column}{.5\textwidth}
\[
y\in\left\{{0,1,2,\dots,n}\right\}
\]
\[
h_\theta(x) = g(\theta^Tx)
\]
\[
g(z) = \frac{1}{1+e^{-z}}\]
\end{column}
\begin{column}{.5\textwidth}
\begin{figure}[tbp]
\centering
\includegraphics[width=1.0\textwidth]{regressionPresentation-sigmoidFunction}
\end{figure}
\end{column}
\end{columns}
\end{frame}

\section{Logistische Regression: Decision Boundary}
\begin{frame}[fragile]{Logistische Regression: Decision Boundary}
\begin{small}
<<admissionDataGLM, fig=true, echo=false, include=false,width=3,height=3>>=
mdl <- glm(admitted~exam1+exam2,data=admissionData,family="binomial")
slope <- coef(mdl)[2]/(-coef(mdl)[3])
intercept <- coef(mdl)[1]/(-coef(mdl)[3])
library(lattice)
xyplot(exam1 ~ exam2, data=admissionData, groups=admitted, 
            panel=function(...) {
                panel.xyplot(...)
                panel.abline(intercept,slope)
                panel.grid(...)
                })
@
%<<glmSummary,echo=false>>=
%summary(mdl)
%@
\begin{figure}[tbp]
\centering
\includegraphics[width=0.5\textwidth]{regressionPresentation-admissionDataGLM}
\end{figure}

\end{small}
\end{frame}

\section{Logistische Regression: Kostenfunktion}
\begin{frame}[fragile]{Logistische Regression: Kostenfunktion}
\begin{small}
\[
J(\theta) = \frac{1}{m}\sum_{i=1}^{m}Cost(h_\theta(x^{(i)}),y^{(i)})
\]
\begin{equation*}
Cost(h_\theta(x),y) = \begin{cases}
                        -\log(h_\theta(x))      & if\:y = 1\\
                        -\log(1-h_\theta(x))    & if\:y = 0 \\
                    \end{cases}
\end{equation*}
\end{small}
\end{frame}

\section{Regularisierung}
\begin{frame}[fragile]{Regularisierung}
\begin{small}
picture: overfitting
\[
J(\theta) = \frac{1}{m}\sum_{i=1}^{m}Cost(h_\theta(x^{(i)}),y^{(i)}) + \frac{\lambda}{2m}\sum_{j=1}^{n}\theta_j^2
\]
\end{small}
\end{frame}

\section{Maximum Likelihood Schätzer}
\begin{frame}[fragile]{Maximum Likelihood Schätzer}
\begin{small}
MLE is identical to OLS under the normality assumption for the error terms.
\[
P(Y_i) \sim \mathcal{N}(h_\theta(x),\sigma^2)
\]
f: Wahrscheinlichkeitsfunktion
\[
L(\theta) = f(x|\theta)
\]
\[
L(\hat{\theta}) = \underset{\theta}{\operatorname{argmax}} L(\theta)
\]
then it is an optimizing problem
\end{small}
\end{frame}

\section{Bayes'sche Lineare Regression}
\begin{frame}[fragile]{Bayes'sche Lineare Regression}
\begin{small}
coincides with maximum likelihood given a uniform prior distribution
data is supplemented with additional information in the form of a prior probability distribution.
\[
gegeben:\:f(x|\theta), L(\theta), f(\theta)
\]
\[
P(\theta) \sim \mathcal{N}(\mu_0,S_0)
\]
\[
P(\theta|y) \sim \mathcal{N}(\mu,S)
\]

\end{small}
\end{frame}

\section{Anwendung}
\begin{frame}{Anwendung}
Phylogenetic Trees: wikipedia
\end{frame}
\begin{frame}
A displayed formula:
\[
  \int_{-\infty}^\infty e^{-x^2} \, dx = \sqrt{\pi}
\]

An itemized list:

\begin{itemize}
  \item itemized item 1
  \item itemized item 2
  \item itemized item 3
\end{itemize}

\begin{theorem}
  In a right triangle, the square of hypotenuse equals
  the sum of squares of two other sides.
\end{theorem}

\end{frame}

\end{document}
